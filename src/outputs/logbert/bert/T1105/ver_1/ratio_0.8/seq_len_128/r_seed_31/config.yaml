default:
  dir_name: outputs
  resource: local
  num_workers: 16
  epochs: 200
  r_seed: 31
  device_id: cuda:3
  deterministic: true
  check_val_every_n_epoch: 1
  early_stop_patience: 20
  monitor:
    name: ValTotal
    mode: min
network:
  ver: logbert
  encoder:
    name: bert
    hidden_size: 256
    layer_num: 4
    attn_heads: 4
    dropout: 0.1
  is_logkey: true
  is_time: false
loss:
  num: 2
  mask:
    bias: 1.0
  hypersphere:
    bias: 0.0
dataset:
  name: T1105
  version: 1
  parser: true
  train_ratio: 0.8
  another_method: true
  dataset_dir: ../data/processed/Integrated
  sample:
    window_size: 128
    adaptive_window: true
    seq_len: 128
    min_len: 10
    mask_ratio: 0.65
    sample_ratio: 1
    valid_size: 0.1
  vocab:
    name: wordvocab
    vocab_size: 60
    min_freq: 1
eval:
  hypersphere_loss_test: false
  num_candidates: 15
optimizer:
  name: Adam
  scheduler:
    name: cosine
  hp:
    lr: 1.0e-05
    weight_decay: 0.0005
    lr_decay: 0.0001
    lr_warmup_step: 10
    lr_warmup_init: 1.0e-06
    warmup_prefix: false
    batch_size: 32
out_dir: outputs/logbert/bert/T1105/ver_1/ratio_0.8/seq_len_128/r_seed_31/
execute_config_name: bert/test
override_cmd:
- dataset.sample.seq_len=128
